
buildscript {
    repositories  {
        maven {
        url "https://plugins.gradle.org/m2/"
        }
    }
    dependencies {
        classpath 'gradle.plugin.com.github.johnrengelman:shadow:7.1.0'
    }
}

apply plugin: 'com.github.johnrengelman.shadow'
apply plugin: 'java'
apply plugin: 'eclipse'
apply plugin: 'application'
apply plugin: 'jacoco'



mainClassName = "org.zuinnote.hadoop.office.example.driver.Excel2CSVDriver"
compileJava.options.encoding = 'UTF-8'
sourceCompatibility = 1.8
version = '0.1.0'



shadowJar {
   relocate 'org.apache.commons.compress', 'hadoopoffice.shade.org.apache.commons.compress'
     manifest {
       attributes 'Implementation-Title': 'Example - MR job (ExcelInput) for reading Excel files using hadoopoffice', 'Implementation-Version': version
     }
	baseName = 'example-ho-mr-excelinput'
    classifier = ''

    exclude 'META-INF/*.RSA', 'META-INF/*.SF','META-INF/*.DSA' // remove signature digests of other libraries
}


repositories {
    mavenCentral()
    mavenLocal()
}


jacocoTestReport {
    reports {
        xml.enabled true
        csv.enabled true
    }
}


configurations {
	provided
	testProvided
	testIntegrationCompile.extendsFrom testCompile
    testIntegrationRuntime.extendsFrom testRuntime
}

eclipse {

  classpath {
    plusConfigurations += [ configurations.provided ]
    plusConfigurations += [ configurations.testProvided ]
    plusConfigurations += [ configurations.testIntegrationCompile ]
    plusConfigurations += [ configurations.testIntegrationRuntime ]
  }
}

javadoc.classpath += configurations.provided



sourceSets {
    main.compileClasspath += configurations.provided
    test.compileClasspath += configurations.provided
    test.runtimeClasspath += configurations.provided
     testIntegration {
        java {
            compileClasspath += main.output + test.output + configurations.provided
            runtimeClasspath += main.output + test.output + configurations.provided
            srcDir file('src/integration-test/java')
        }
        resources.srcDir file('src/integration-test/resources')
    }
}



dependencies {
   // hadoop lib for driver
     compileOnly("org.apache.hadoop:hadoop-client:3.3.0")
     // hadoopoffice library
   implementation("com.github.zuinnote:hadoopoffice-fileformat:1.6.4")

       testImplementation group: 'org.junit.jupiter', name: 'junit-jupiter', version: '5.8.2'

testIntegrationImplementation("com.github.zuinnote:hadoopoffice-fileformat:1.6.4")
 testImplementation("org.apache.logging.log4j:log4j-api:2.17.2")
  testIntegrationImplementation("org.apache.logging.log4j:log4j-api:2.17.2")
// for integration testing we can only use 2.7.x, because higher versions of Hadoop have a bug in minidfs-cluster. Nevertheless, the library itself works also with higher Hadoop versions 
// see https://issues.apache.org/jira/browse/HDFS-5328
testIntegrationImplementation("org.apache.hadoop:hadoop-common:2.7.0")
     testIntegrationImplementation("org.apache.hadoop:hadoop-client:2.7.0")
       testIntegrationImplementation group: 'org.junit.jupiter', name: 'junit-jupiter', version: '5.8.2'
     testIntegrationImplementation group: 'org.apache.hadoop', name: 'hadoop-minicluster', version: '2.7.0'
}





test {
    systemProperty "java.awt.headless", "true"
    testLogging.showStandardStreams = true
    useJUnitPlatform()
}

task testIntegration(type: Test) {
    systemProperty "java.awt.headless", "true"
      testLogging.showStandardStreams = false
    testClassesDirs = sourceSets.testIntegration.output.classesDirs
    classpath = sourceSets.testIntegration.runtimeClasspath
    useJUnitPlatform()
}

1
2

check.dependsOn testIntegration
testIntegration.mustRunAfter test


artifacts {
    archives shadowJar
}
